---
title: "GP_spatio_temporal_forecasting"
author: "Sahoko"
date: "11/1/2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Setup
Load libraries and set up paths
```{r}
library(cmdstanr)
set_cmdstan_path('/Users/f.panero/Library/Mobile Documents/com~apple~CloudDocs/Documents/cmdstan/')
check_cmdstan_toolchain(fix = TRUE, quiet = TRUE)
cmdstanr::cmdstan_make_local(cpp_options = list(CXX="arch -arch arm64e clang++"))
library(ggmcmc)
```

```{r}
base_path = '/Users/f.panero/Library/Mobile Documents/com~apple~CloudDocs/Documents/Research/GP_food_insecurity/Food-insecurity-GP-forecasting/'
stan_path = paste0(base_path, 'Code/Stan/')
data_path = paste0(base_path, 'Data/Foini2023/')
frequency = 'weekly'
```
## Read and prepare data
Read data
```{r}
country_list = list.files(path = paste0(data_path,'output_data/'))
print(country_list)
# select country
countries = country_list[1] #country_list[c(1,5,6,7)]
print(countries)
j = 0
for(i in countries){
  file = paste0(data_path,'output_data/', i,'/',i,'-long.csv')
  file_loc = paste0(data_path,'output_data/', i,'/',i,'-location.csv')
  if(j == 0){
    df = read.csv(file, header = TRUE)
    df$country = rep(i, dim(df)[1])
    df_loc = read.csv(file_loc, header = TRUE)
    df_loc$country = rep(i, dim(df_loc)[1])
  }
  else
  {
    y = read.csv(file, header = TRUE)
    y$country = rep(i, dim(y)[1])
    df = rbind(df, y)
    y = read.csv(file_loc, header = TRUE)
    y$country = rep(i, dim(y)[1])
    df_loc = rbind(df_loc, y)
  }
  j = j + 1
}
df$Datetime = as.Date(df$Datetime, tz='GMT')
colnames(df)[colnames(df)=='FCG'] = 'FCS'
#region_list = df_loc$region
```


```{r}
#Limit the data from "2019-11-01 GMT" to"2022-03-31 GMT"
df = df[df$Datetime>=as.Date('2019-11-01', tz='GMT') & df$Datetime<=as.Date('2022-03-31', tz='GMT'),]
if (frequency == 'weekly') {
  N1 = dim(df_loc)[1]
  N2 = dim(df)[1]/N1
  week_id = c()
  for (i in 1:range(N1)) {
    week_id = c(week_id, (i - 1) * N2 + seq(1, N2, 7))
  }
  df = df[week_id, ]
}
df_country = vector(mode = 'list', length = length(countries))
df_loc_country = vector(mode = 'list', length = length(countries))
for (c in 1:length(countries)){
  df_country[[c]] = df[df$country == countries[c], ]
  df_loc_country[[c]] = df_loc[df_loc$country == countries[c], ]
}
```

Prepare data
```{r}
N1 = N2 = X1 = X2 = y = z = Y = Z = vector(mode = 'list', length = length(countries))

for (c in 1:length(countries)){
  if (frequency == 'daily') {
  N1[[c]] = dim(df_loc_country[[c]])[1] # number of regions
  N2[[c]] = dim(df_country[[c]])[1]/N1[[c]] # length of ts for each region
  X1[[c]] = df_loc_country[[c]][, c('Easting','Northing')] / 10000
  X2[[c]] = matrix(1:N2[[c]], N2[[c]], 1)
  y[[c]] = df_country[[c]]$FCS
  z[[c]] = log(y[[c]]/(100-y[[c]]))
  Y[[c]] = matrix(y[[c]], N2[[c]], N1[[c]])
  Z[[c]] = matrix(z[[c]], N2[[c]], N1[[c]])
  } else if (frequency == 'weekly') {
  N1[[c]] = dim(df_loc_country[[c]])[1]
  N2[[c]] = dim(df_country[[c]])[1]/N1[[c]]
  X1[[c]] =  df_loc_country[[c]][, c('Easting','Northing')] / 10000
  X2[[c]] = matrix(1:N2[[c]], N2[[c]], 1)
  y[[c]] = df_country[[c]]$FCS
  z[[c]] = log(y[[c]]/(100-y[[c]]))
  Y[[c]] = matrix(y[[c]], N2[[c]], N1[[c]])
  Z[[c]] = matrix(z[[c]], N2[[c]], N1[[c]])
  }
  print(paste('country:', countries[c], ', numb of regions:', N1[[c]], ', length of ts per region:', N2[[c]]))
}

```

Divide to training - test data
```{r}

cv_num = 1 # due to the structure we decided to give to train\test split (7 months training + 1 month test) this value can range from 1 to 4. Right now if you select a 1-fold cv you are going to start on the 2019-11-01. If you want to change this, be mindful that other things will have to change!
if (frequency == 'daily') {
  tr_st = rep(as.Date('2019-11-01',tz='GMT'), cv_num)
  tr_en = as.Date(c('2020-05-31', '2020-12-31', '2021-07-31', '2022-02-28'), tz='GMT')
  tes_st = tr_en + 1
  tes_en = as.Date(c('2020-06-30', '2021-01-31', '2021-08-31', '2022-03-31'), tz='GMT')
} else if (frequency == 'weekly') {
  tr_st = rep(as.Date('2019-11-01',tz='GMT'), cv_num)
  tr_en = as.Date(c('2020-05-29', '2020-12-25', '2021-07-30', '2022-02-25'), tz='GMT')
  tes_st = tr_en + 7
  tes_en = tr_en + 28
}

X2_tr = z_tr = y_tr = ix_tr = vector(mode = 'list', length = length(countries))
X2_tes = z_tes = y_tes = ix_tes = vector(mode = 'list', length = length(countries))
for (c in 1:length(countries)){
  X2_tr[[c]] = z_tr[[c]] = y_tr[[c]] = ix_tr[[c]] = vector(mode = 'list', length = cv_num)
  X2_tes[[c]] = z_tes[[c]] = y_tes[[c]] = ix_tes[[c]] = vector(mode = 'list', length = cv_num)
}

for (c in 1:length(countries)){
  for (i in 1:cv_num){
    ix_tr[[c]][[i]]  = 1:which(df_country[[c]]$Datetime[1:N2[[c]]]==tr_en[i])
    ix_tes[[c]][[i]] = which(df_country[[c]]$Datetime[1:N2[[c]]]==tes_st[i]):which(df_country[[c]]$Datetime[1:N2[[c]]]==tes_en[i])
    X2_tr[[c]][[i]]  = matrix(ix_tr[[c]][[i]], length(ix_tr[[c]][[i]]), 1)
    X2_tes[[c]][[i]] = matrix(ix_tes[[c]][[i]], length(ix_tes[[c]][[i]]), 1)
    z_tr[[c]][[i]] = c(Z[[c]][ix_tr[[c]][[i]],])
    z_tes[[c]][[i]] = c(Z[[c]][ix_tes[[c]][[i]],])
    y_tr[[c]][[i]] = c(Y[[c]][ix_tr[[c]][[i]],])
    y_tes[[c]][[i]] = c(Y[[c]][ix_tes[[c]][[i]],])
  }
}
print(paste('training set list is made of ', length(X2_tr), 'countries and ', length(X2_tr[[1]]), ' cross validation periods'))
```

## Stan - THE CODE FROM NOW ON NEEDS TO BE CAREFULLY CHECKED and possibly revised
Compile Stan code
```{r}
#stan_file = paste0(stan_path,'GPst_est_sqcenfBM.stan') #Using square & centred Brownian motion kernel (similar property to cubic spline)
stan_file = paste0(stan_path,'GPst_est.stan') # Using SE kernel
#stan_file = paste0(stan_path,'GPst_est_exponential.stan') # Using SE kernel
mod = cmdstan_model(stan_file,  include_paths = stan_path)
#stan_file_pred = paste0(stan_path,'GPst_pred_sqcenfBM.stan')
stan_file_pred = paste0(stan_path,'GPst_pred.stan')
#stan_file_pred = paste0(stan_path,'GPst_pred_exponential.stan')
modpred = cmdstan_model(stan_file_pred,  include_paths = stan_path)
#params = c('alpha0','alpha1','alpha2','sigma') #BM kernel
params = c('alpha0','alpha1','alpha2','rho1','rho2','sigma') #SE / exponential / Matern kernels
```
MCMC sampling for BM kernel
```{r}
ft_bm = list()
for (c in length(countries)){
  for (i in 1:cv_num){
  data = list(N1 = N1[[c]], N2 = length(ix_tr[[c]][[i]]), X1 = X1[[c]], X2 = c(X2_tr[[c]][[i]]), y = z_tr[[c]][[i]], Hurst1 = 0.5, Hurst2 = 0.5)
  fit_bm[[c]] = mod$sample(
  data = data, 
  #seed = 725, 
  #seed = 3283,
  seed = 121,
  iter_warmup = 200,
  iter_sampling = 300,
  save_warmup = TRUE,
  chains = 2, 
  parallel_chains = 2,
  refresh = 50
  )
  fit_bm[[c]]$save_output_files(dir = paste0(base_path,"Output"), basename = paste0('fcst_training_bm_', as.character(i), '_country_' , countries[c]), timestamp = TRUE, random = TRUE)
}
}

```
MCMC sampling for SE kernel
```{r}
fit_se = list()
for (i in 1:cv_num){
  data = list(N1 = N1[[c]], N2 = length(ix_tr[[c]][[i]]), X1 = X1[[c]], X2 = c(X2_tr[[c]][[i]]), y = z_tr[[c]][[i]])
  fit_se[[c]] = mod$sample(
  data = data, 
  #seed = 725, 
  #seed = 3283,
  seed = 311,
  iter_warmup = 200,
  iter_sampling = 100,
  save_warmup = TRUE,
  chains = 2, 
  parallel_chains = 2,
  refresh = 10
  )
  fit_se[[c]]$save_output_files(dir = paste0(base_path,"Output"), basename = paste0('fcst_training_se_', as.character(i), '_country_' , countries[c]), timestamp = TRUE, random = TRUE)
}
```

```{r}
for (c in length(countries)){
  # post_mean_bm = fit_bm[[c]]$summary(variables = params)$mean
  # fit_bm[[c]]$summary(variables = append(params, 'lp__'))
  
  post_mean_se = fit_se[[c]]$summary(variables = params)$mean
  fit_se[[c]]$summary(variables = append(params, 'lp__'))
}
```

```{r}
# post_samples_bm = fit_bm$draws(format = "df",  inc_warmup = F)
# post_samples_bm$chain = as.character(post_samples_bm$.chain)
# for (i in 1:length(params)){
#   gg = ggplot(data=post_samples_bm, aes_string(x=".iteration", y = params[i], color="chain"))+
#   geom_line() + theme_minimal() + ggtitle('BM')
#   print(gg)
# }
# for (i in 1:length(params)){
#   gg = ggplot(data=post_samples_bm[post_samples_bm$.chain==2,], aes_string(x=".iteration", y = params[i]))+
#   geom_line() + theme_minimal() + ggtitle('BM')
#   print(gg)
# }
for (c in length(countries)){
  post_samples_se[[c]] = fit_se[[c]]$draws(format = "df",  inc_warmup = F)
  post_samples_se[[c]]$chain = as.character(post_samples_se[[c]]$.chain)
  for (i in 1:length(params)){
    gg = ggplot(data=post_samples_se[[c]], aes_string(x=".iteration", y = params[i], color="chain"))+
    geom_line() + theme_minimal() + ggtitle('SE')
    print(gg)
  }
  for (i in 1:length(params)){
    gg = ggplot(data=post_samples_se[[c]][post_samples_se[[c]]$.chain==2,], aes_string(x=".iteration", y = params[i]))+
    geom_line() + theme_minimal() + ggtitle('SE')
    print(gg)
  }
}

```
Optimsation for BM kernel - THIS ONE NOT WORKING
```{r}
RMSE = MAE = rep(NA,cv_num)
for (i in 1:cv_num){
  N2_tes = length(ix_tes[[i]])
  N2_tr = length(ix_tr[[i]])
  data = list(N1 = N1, N2 = length(ix_tr[[i]]), X1 = X1, X2 = X2_tr[[i]][,1], y = z_tr[[i]], Hurst1 = 0.5, Hurst2 = 0.5)
  fit_optim = mod$optimize(data = data, seed=763)
  post_mean = fit_optim$summary(variables = params)$estimate
  data_pred = list(N1 = N1, N2 = length(ix_tr[[i]]),
            X1 = X1, X2 = X2_tr[[i]], y = z_tr[[i]], 
            n1 = N1, n2 = N2_tes,
            x1_new = X1,  x2_new = X2_tes[[i]],
            Hurst1 = 0.5, Hurst2 = 0.5,
            alpha0 = fit_optim$summary(variables = 'alpha0')$estimate, 
            alpha1 = fit_optim$summary(variables = 'alpha1')$estimate, 
            alpha2 = fit_optim$summary(variables = 'alpha2')$estimate, 
            sigma = fit_optim$summary(variables = 'sigma')$estimate,
            rho1 = fit_optim$summary(variables = 'rho1')$estimate, 
            rho2 = fit_optim$summary(variables = 'rho2')$estimate
            )
  pred = modpred$sample(
  data = data_pred, 
  iter_warmup = 1,
  iter_sampling = 1000,
  chains = 1, 
  refresh = 100,
  fixed_param = TRUE)
  predfit = rstan::read_stan_csv(pred$output_files())
  pred$save_output_files(dir = paste0(base_path,"Output"), basename = paste0('fcst_bm_',as.character(i), '_',country), timestamp = TRUE, random = TRUE)
  ######
  # Extracting result
  n_terms = 4 # change here depending on the model
  cnames = c('const','space','time','space_time')
  terms = c('mu0', 'mu1', 'mu2', 'mu12')
  df_pred = as.data.frame(matrix(NA, N1*N2_tes,n_terms))
  colnames(df_pred) = cnames[1:n_terms]
  #main terms
  df_pred$const = rep(colMeans(as.matrix(predfit, pars = c(terms[1]))), times=(N1*N2_tes))
  df_pred$space = rep(colMeans(as.matrix(predfit, pars = c(terms[2]))), each=N2_tes)
  df_pred$time = rep(colMeans(as.matrix(predfit, pars = c(terms[3]))), times=N1)
  # two way int
  df_pred$space_time = colMeans(as.matrix(predfit, pars = c(terms[4])))
  ######
  dz_hat = rowSums(df_pred)
  df_pred$y_hat = 100/(1+exp(-z_hat))
  df_pred$y_true = y_tes[[i]]
  df_pred$y_residual = df_pred$y_hat - df_pred$y_true
  df_pred$region = rep(df_loc$region, each = N2_tes)
  df_pred$Datetime = rep(as.POSIXct(df$Datetime[1:N2][ix_tes[[i]]], tz='GMT'), times=N1)
  RMSE[i] = sqrt(mean((df_pred$y_residual)^2))
  MAE[i] = mean(sqrt((df_pred$y_residual)^2))
  cat('RMSE for', country, ':', RMSE[i],'\n')
  cat('MAE for', country, ':', MAE[i],'\n')
  write.csv(df_pred,paste0(base_path,'Output/cv_fcst_bm_',as.character(i), '_', country,'.csv'))
}
```

Optimsation for SE kernel
```{r}
RMSE = c(); MAE = c()
for (i in 1:cv_num){
  N2_tes = length(ix_tes[[i]])
  N2_tr = length(ix_tr[[i]])
  data = list(N1 = N1, N2 = N2_tr, X1 = X1, X2 = c(X2_tr[[i]]), y = z_tr[[i]])
  fit_optim = mod$optimize(data = data, seed=123)
  post_mean = fit_optim$summary(variables = params)$estimate
  data_pred = list(N1 = N1, N2 = N2_tr,
            X1 = X1, X2 = X2_tr[[i]], y = z_tr[[i]], 
            n1 = N1, n2 = N2_tes,
            x1_new = X1,  x2_new = X2_tes[[i]],
            alpha0 = fit_optim$summary(variables = 'alpha0')$estimate, 
            alpha1 = fit_optim$summary(variables = 'alpha1')$estimate, 
            alpha2 = fit_optim$summary(variables = 'alpha2')$estimate, 
            rho1 = fit_optim$summary(variables = 'rho1')$estimate, 
            rho2 = fit_optim$summary(variables = 'rho2')$estimate, 
            sigma = fit_optim$summary(variables = 'sigma')$estimate
            )
  rm(fit_optim)
  pred = modpred$sample(
    data = data_pred, 
    iter_warmup = 1,
    iter_sampling = 1000,
    chains = 1, 
    refresh = 100,
    fixed_param = TRUE)
  predfit = rstan::read_stan_csv(pred$output_files())
  pred$save_output_files(dir = paste0(base_path,"Output"), basename = paste0('fcst_se_',as.character(i), '_',country), timestamp = TRUE, random = TRUE)
  post_z_samples = pred$draws(format = "df",  inc_warmup = F)
  post_y_samples = 100/(1+exp(-post_z_samples[,1:(N1*N2_tes)]))
  df_pred = as.data.frame(matrix(NA, N1*N2_tes,0))
  df_pred$y_hat = colMeans(post_y_samples)
  df_pred$y_true = y_tes[[i]]
  df_pred$y_residual = df_pred$y_hat - df_pred$y_true
  df_pred$region = rep(df_loc$region, each = N2_tes)
  df_pred$Datetime = rep(as.Date(df$Datetime[1:N2][ix_tes[[i]]], tz='GMT'), times=N1)
  RMSE[i] = sqrt(mean((df_pred$y_residual)^2))
  MAE[i] = mean(sqrt((df_pred$y_residual)^2))
  cat('RMSE for', country, ':', RMSE[i],'\n')
  cat('MAE for', country, ':', MAE[i],'\n')
  write.csv(df_pred,paste0(base_path,'Output/cv_fcst_se_',as.character(i), '_', country,'.csv'))
  post_y_samples = cbind(post_y_samples, post_z_samples[,(N1*N2_tes+1):dim(post_z_samples)[2]])
  write.csv(post_y_samples,paste0(base_path,'Output/post_samples_cv_fcst_se_',as.character(i), '_', country,'.csv'))
}
mean(RMSE);
mean(MAE);
# Burkina Faso
#7.286001
#5.969191
```

Optimsation for exp kernel
```{r}
#RMSE = c(); MAE = c()
for (i in 1:cv_num){
  N2_tes = length(ix_tes[[i]])
  N2_tr = length(ix_tr[[i]])
  data = list(N1 = N1, N2 = N2_tr, X1 = X1, X2 = c(X2_tr[[i]]), y = z_tr[[i]])
  fit_optim = mod$optimize(data = data, seed=172)
  post_mean = fit_optim$summary(variables = params)$estimate
  data_pred = list(N1 = N1, N2 = N2_tr,
            X1 = X1, X2 = X2_tr[[i]], y = z_tr[[i]], 
            n1 = N1, n2 = N2_tes,
            x1_new = X1,  x2_new = X2_tes[[i]],
            alpha0 = fit_optim$summary(variables = 'alpha0')$estimate, 
            alpha1 = fit_optim$summary(variables = 'alpha1')$estimate, 
            alpha2 = fit_optim$summary(variables = 'alpha2')$estimate, 
            rho1 = fit_optim$summary(variables = 'rho1')$estimate, 
            rho2 = fit_optim$summary(variables = 'rho2')$estimate, 
            sigma = fit_optim$summary(variables = 'sigma')$estimate
            )
  rm(fit_optim)
  pred = modpred$sample(
  data = data_pred, 
  iter_warmup = 1,
  iter_sampling = 1000,
  chains = 1, 
  refresh = 100,
  fixed_param = TRUE)
  predfit = rstan::read_stan_csv(pred$output_files())
  pred$save_output_files(dir = paste0(base_path,"Output"), basename = paste0('fcst_exponential_',as.character(i), '_',country), timestamp = TRUE, random = TRUE)
  post_z_samples = pred$draws(format = "df",  inc_warmup = F)
  post_y_samples = 100/(1+exp(-post_z_samples[,1:(N1*N2_tes)]))
  df_pred = as.data.frame(matrix(NA, N1*N2_tes,0))
  df_pred$y_hat = colMeans(post_y_samples)
  df_pred$y_true = y_tes[[i]]
  df_pred$y_residual = df_pred$y_hat - df_pred$y_true
  df_pred$region = rep(df_loc$region, each = N2_tes)
  df_pred$Datetime = rep(as.Date(df$Datetime[1:N2][ix_tes[[i]]], tz='GMT'), times=N1)
  RMSE[i] = sqrt(mean((df_pred$y_residual)^2))
  MAE[i] = mean(sqrt((df_pred$y_residual)^2))
  cat('RMSE for', country, ':', RMSE[i],'\n')
  cat('MAE for', country, ':', MAE[i],'\n')
  write.csv(df_pred, paste0(base_path,'Output/cv_fcst_exponential_',as.character(i), '_', country,'.csv'))
  post_y_samples = cbind(post_y_samples, post_z_samples[,(N1*N2_tes+1):dim(post_z_samples)[2]])
  write.csv(post_y_samples,paste0(base_path,'Output/post_samples_cv_fcst_exponential_',as.character(i), '_', country,'.csv'))
}
mean(RMSE);
mean(MAE);
# Burkina Faso
#7.286001
#5.969191
```

Plot
```{r}
for (i in 1:cv_num){
    df_pred =  read.csv(paste0(base_path, '/Output/cv_fcst_exponential_', as.character(i), '_', country,'.csv'), header = TRUE)
  df_pred$Datetime = as.POSIXct(df_pred$Datetime)
  gg = ggplot(df_pred, aes(x=Datetime,y=y_residual,color=region)) + geom_line() 
  print(gg)
}
```

#Plot
```{r}
i = 1
N2_tes = length(ix_tes[[i]])
N2_tr = length(ix_tr[[i]])
df_plot = df
Y_pred = matrix(NA, N2,N1)
Y_true = matrix(NA, N2,N1)
Y_pred[ix_tr[[i]],] = Y[ix_tr[[i]],]
Y_true[ix_tr[[i]],] = Y[ix_tr[[i]],]
Y_pred[ix_tes[[i]],] = matrix(df_pred$y_hat, N2_tes, N1)
df_plot$training = c(Y_true)
df_plot$forecast = c(Y_pred)
Y_true[ix_tes[[i]],] = Y[ix_tes[[i]],]
df_plot$true = c(Y_true)
df_plot$error = df_plot$forecast - df_plot$true 
df_plot = df_plot[is.na(df_plot$forecast)!=TRUE,]
```

```{r}
y_max = max(df_plot$true); y_min = min(df_plot$true)
date_th = df_plot$Datetime[N2_tr]
gg_tr = ggplot(df_plot, aes(x=Datetime,y=forecast,color=region)) + geom_line() + ylim(y_min,y_max)  +
 #xlim(as.Date("2021-09-01"),df_plot$Datetime[length(df_plot$Datetime)])+
       geom_vline(xintercept = date_th,linetype=4) 
gg_tr
gg_pred = ggplot(df_plot, aes(x=Datetime,y=true,color=region)) + geom_line() + ylim(y_min,y_max)  +
  #xlim(as.Date("2021-09-01"),df_plot$Datetime[length(df_plot$Datetime)])+
       geom_vline(xintercept = date_th,linetype=4)
gg_pred
gg = ggplot(df_plot, aes(x=Datetime,y=training,color=region)) + geom_line() + ylim(y_min,y_max) #+
 #xlim(as.Date("2021-09-01"),df_plot$Datetime[length(df_plot$Datetime)])
gg
```




