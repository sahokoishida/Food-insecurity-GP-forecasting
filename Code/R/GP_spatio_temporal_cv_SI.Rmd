---
title: "GP_spatio_temporal_forecasting"
author: "Sahoko"
date: "11/1/2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Setup
Load libraries and set up paths

```{r}
library(cmdstanr)
library(ggmcmc)
library(dplyr)
```

```{r}
base_path = '/Users/sahoko/GitHub/Food-insecurity-GP-forecasting/'
stan_path = paste0(base_path, 'Code/Stan/')
data_path = paste0(base_path, 'Data/Foini2023/')
frequency = 'weekly' # or 'weekly average'
#frequency = 'weekly average'
```

## Read and prepare data
Read data
```{r}
country_list = list.files(path = paste0(data_path,'output_data/'))
print(country_list)
# select country
countries = country_list[1] #country_list[c(1,5,6,7)]
print(countries)
j = 0
for(i in countries){
  file = paste0(data_path,'output_data/', i,'/',i,'-long.csv')
  file_loc = paste0(data_path,'output_data/', i,'/',i,'-location.csv')
  if(j == 0){
    df = read.csv(file, header = TRUE)
    df$country = rep(i, dim(df)[1])
    df_loc = read.csv(file_loc, header = TRUE)
    df_loc$country = rep(i, dim(df_loc)[1])
  }
  else
  {
    y = read.csv(file, header = TRUE)
    y$country = rep(i, dim(y)[1])
    df = rbind(df, y)
    y = read.csv(file_loc, header = TRUE)
    y$country = rep(i, dim(y)[1])
    df_loc = rbind(df_loc, y)
  }
  j = j + 1
}
df$Datetime = as.Date(df$Datetime, tz='GMT')
colnames(df)[colnames(df)=='FCG'] = 'FCS'
region_list = df_loc$region
```


```{r}
#Limit the data from "2019-11-01 GMT" to"2022-03-31 GMT"
df = df[df$Datetime>=as.Date('2019-11-01', tz='GMT') & df$Datetime<=as.Date('2022-03-31', tz='GMT'),]
if (frequency%in%c('weekly','weekly average')){
    N1 = dim(df_loc)[1]
    N2 = dim(df)[1]/N1
    week_id = c()
    for (i in 1:range(N1)) {
      week_id = c(week_id, (i - 1) * N2 + seq(1, N2, 7))
    }
    if (frequency=='weekly'){
      df = df[week_id, ]
    } else if (frequency=='weekly average') {
      df_tmp = df
      df_tmp$week_num = rep(rep(1:(N2/7),each=7),times=N1)
      FCS_avg <- df_tmp %>% 
        group_by(region,week_num) %>%
        summarise(across(FCS, mean, na.rm = TRUE))
      df = df[week_id, ]
      df$FCS = FCS_avg$FCS
    }
}

df_country = vector(mode = 'list', length = length(countries))
df_loc_country = vector(mode = 'list', length = length(countries))
for (c in 1:length(countries)){
  df_country[[c]] = df[df$country == countries[c], ]
  df_loc_country[[c]] = df_loc[df_loc$country == countries[c], ]
}
```

```{r}
gg = ggplot(df, aes(x=Datetime, y=FCS, color=region)) + geom_line()+theme_minimal()+
  xlim(as.Date("2020-04-01"),as.Date("2020-09-01"))
gg
df_pl_tmp = df
df_pl_tmp = df[df$Datetime>=as.Date(tr_st, tz='GMT') & df$Datetime<=as.Date(tr_en[1], tz='GMT'),]
fig <- plot_ly(data = df_pl_tmp, x = ~Datetime, y = ~FCS, color=~region, type = 'scatter', mode = 'lines')
fig
```

```{r}
#df_pl_tmp = df
df_pl_tmp$Fatal.per.pop = (df_pl_tmp$Fatalities/df_pl_tmp$Population)*10000
#df_pl_tmp = df_pl_tmp[df_pl_tmp$Datetime>=as.Date("2020-04-01", tz='GMT') & df_pl_tmp$Datetime<=as.Date("2020-09-01", tz='GMT'),]
fig <- plot_ly(data = df_pl_tmp, x = ~Datetime, y = ~Fatal.per.pop, color=~region, type = 'scatter', mode = 'lines')
fig
fig <- plot_ly(data = df_pl_tmp, x = ~Datetime, y = ~Fatalities, color=~region, type = 'scatter', mode = 'lines')
fig
fig <- plot_ly(data = df_pl_tmp, y = ~Ramadan, x = ~Datetime, color=~region, type = 'scatter',mode='lines')
fig
fig <- plot_ly(data = df_pl_tmp, y = ~Price.cereals.and.tubers, x = ~Datetime, color=~region, type = 'scatter')
fig
```

```{r}
fig <- plot_ly(data = df_pl_tmp, x = ~log(Fatalities), y = ~FCS, color=~region, type = 'scatter')
fig
fig <- plot_ly(data = df_pl_tmp, x = ~Fatal.per.pop, y = ~FCS, color=~region, type = 'scatter')
fig
fig <- plot_ly(data = df_pl_tmp[!is.na(df_pl_tmp$NDVI.Anomaly),], x = ~log(Rainfalls..mm.), y = ~FCS, color=~region, type = 'scatter')
fig

fig <- plot_ly(data = df_pl_tmp[!is.na(df_pl_tmp$NDVI.Anomaly),], x = ~(X3.Months.Anomaly.Rainfalls....-100), y = ~FCS, color=~region, type = 'scatter')
fig
fig <- plot_ly(data = df_pl_tmp[!is.na(df_pl_tmp$Price.cereals.and.tubers),], x = ~log(Price.cereals.and.tubers), y = ~FCS, color=~region, type = 'scatter')
fig

```


```{r}

colnames(df_pl_tmp)
fig <- plot_ly(data = df_pl_tmp[!is.na(df_pl_tmp$NDVI),], x = ~Datetime, y = ~NDVI, color=~region, type = 'scatter', mode='lines')
fig

fig2 <- plot_ly(data = df_pl_tmp[!is.na(df_pl_tmp$NDVI.Anomaly),], x = ~Datetime, y = ~NDVI.Anomaly, color=~region, type = 'scatter', mode='lines')
fig2
```

Prepare data
```{r}
N1 = N2 = X1 = X2 = y = z = Y = Z = vector(mode = 'list', length = length(countries))

for (c in 1:length(countries)){
  if (frequency == 'daily') {
  N1[[c]] = dim(df_loc_country[[c]])[1] # number of regions
  N2[[c]] = dim(df_country[[c]])[1]/N1[[c]] # length of ts for each region
  X1[[c]] = df_loc_country[[c]][, c('Easting','Northing')] / 10000
  X2[[c]] = matrix(1:N2[[c]], N2[[c]], 1)
  y[[c]] = df_country[[c]]$FCS
  z[[c]] = log(y[[c]]/(100-y[[c]]))
  Y[[c]] = matrix(y[[c]], N2[[c]], N1[[c]])
  Z[[c]] = matrix(z[[c]], N2[[c]], N1[[c]])
  } else if (frequency %in% c('weekly','weekly average')) {
  N1[[c]] = dim(df_loc_country[[c]])[1]
  N2[[c]] = dim(df_country[[c]])[1]/N1[[c]]
  X1[[c]] =  df_loc_country[[c]][, c('Easting','Northing')] / 10000
  X2[[c]] = matrix(1:N2[[c]], N2[[c]], 1)
  y[[c]] = df_country[[c]]$FCS
  z[[c]] = log(y[[c]]/(100-y[[c]]))
  Y[[c]] = matrix(y[[c]], N2[[c]], N1[[c]])
  Z[[c]] = matrix(z[[c]], N2[[c]], N1[[c]])
  }
  print(paste('country:', countries[c], ', numb of regions:', N1[[c]], ', length of ts per region:', N2[[c]]))
}

```

Divide to training - test data
```{r}
cv_num = 1 # due to the structure we decided to give to train\test split (7 months training + 1 month test) this value can range from 1 to 4. Right now if you select a 1-fold cv you are going to start on the 2019-11-01. If you want to change this, be mindful that other things will have to change!
if (frequency == 'daily') {
  tr_st = rep(as.Date('2019-11-01',tz='GMT'), cv_num)
  #tr_en = as.Date(c('2020-05-31', '2020-12-31', '2021-07-31', '2022-02-28'), tz='GMT')
  tr_en = as.Date(c('2020-12-31', '2021-07-31', '2022-02-28'), tz='GMT')
  tes_st = tr_en + 1
  #tes_en = as.Date(c('2020-06-30', '2021-01-31', '2021-08-31', '2022-03-31'), tz='GMT')
  tes_en = as.Date(c( '2021-01-31', '2021-08-31', '2022-03-31'), tz='GMT')
} else if (frequency %in% c('weekly','weekly average')) {
  tr_st = rep(as.Date('2019-11-01',tz='GMT'), cv_num)
  #tr_en = as.Date(c('2020-05-29', '2020-12-25', '2021-07-30', '2022-02-25'), tz='GMT')
  tr_en = as.Date(c('2020-12-25', '2021-07-30', '2022-02-25'), tz='GMT')
  tes_st = tr_en + 7
  tes_en = tr_en + 28
}

X2_tr = z_tr = y_tr = ix_tr = vector(mode = 'list', length = length(countries))
X2_tes = z_tes = y_tes = ix_tes = vector(mode = 'list', length = length(countries))
for (c in 1:length(countries)){
  X2_tr[[c]] = z_tr[[c]] = y_tr[[c]] = ix_tr[[c]] = vector(mode = 'list', length = cv_num)
  X2_tes[[c]] = z_tes[[c]] = y_tes[[c]] = ix_tes[[c]] = vector(mode = 'list', length = cv_num)
}

for (c in 1:length(countries)){
  for (i in 1:cv_num){
    ix_tr[[c]][[i]]  = 1:which(df_country[[c]]$Datetime[1:N2[[c]]]==tr_en[i])
    ix_tes[[c]][[i]] = which(df_country[[c]]$Datetime[1:N2[[c]]]==tes_st[i]):which(df_country[[c]]$Datetime[1:N2[[c]]]==tes_en[i])
    X2_tr[[c]][[i]]  = matrix(ix_tr[[c]][[i]], length(ix_tr[[c]][[i]]), 1)
    X2_tes[[c]][[i]] = matrix(ix_tes[[c]][[i]], length(ix_tes[[c]][[i]]), 1)
    z_tr[[c]][[i]] = c(Z[[c]][ix_tr[[c]][[i]],])
    z_tes[[c]][[i]] = c(Z[[c]][ix_tes[[c]][[i]],])
    y_tr[[c]][[i]] = c(Y[[c]][ix_tr[[c]][[i]],])
    y_tes[[c]][[i]] = c(Y[[c]][ix_tes[[c]][[i]],])
  }
}
print(paste('training set list is made of ', length(X2_tr), 'countries and ', length(X2_tr[[1]]), ' cross validation periods'))
```


## Stan - THE CODE FROM NOW ON NEEDS TO BE CAREFULLY CHECKED and possibly revised
Compile Stan code: models 
* Kernel: spatial -> centred SE, temporal -> centred SE 
  - Note on the centring. Kernel centring is analogue to data/featuring centring in standard linear regression. For forecasting,ideally, centring should be done using the whole study period (i.e. the beginning of training period to the end of test/forecasting period) but this is computationally costly. If the forecasting period is not long (relative to the training period), it might be justifiable to centre the kernel using only the training period. 
* Error term: RE for the region + i.i.d. Gaussian 

```{r}
# 2 options for centring
#cent_option = "whole" #otherwise cent_option = "training"
cent_option = "training"
if (cent_option=="whole"){
  stan_file = paste0(stan_path,'GPst_est_cent_re2.stan') 
  stan_file_pred = paste0(stan_path,'GPst_pred_cent_re2.stan')
  params = c('alpha0','alpha1','alpha2','rho1','rho2','sigma1','sigma') 

} else if (cent_option=="training"){
  stan_file = paste0(stan_path,'GPst_est_cent_re.stan') 
  stan_file_pred = paste0(stan_path,'GPst_pred_cent_re.stan') 
  params = c('alpha0','alpha1','alpha2','rho1','rho2','sigma1','sigma') 
} else {
  print("Choose a centring option from whole or training")
}
mod = cmdstan_model(stan_file,  include_paths = stan_path)
modpred = cmdstan_model(stan_file_pred,  include_paths = stan_path)
```

Just to check if thee first model worked with the orginal
```{r}
stan_file = paste0(stan_path,'GPst_est.stan') 
stan_file_pred = paste0(stan_path,'GPst_pred.stan')
params = c('alpha0','alpha1','alpha2','rho1','rho2','sigma') 
mod = cmdstan_model(stan_file,  include_paths = stan_path)
modpred = cmdstan_model(stan_file_pred,  include_paths = stan_path)

```


MCMC sampling for SE kernel
```{r}
fit_se = list()
for (i in 1:cv_num){
  data = list(N1 = N1[[c]], N2 = length(ix_tr[[c]][[i]]), X1 = X1[[c]], X2 = X2_tr[[c]][[i]], y = z_tr[[c]][[i]])
  fit_se[[c]] = mod$sample(
  data = data, 
  #seed = 725, 
  #seed = 3283,
  seed = 311,
  iter_warmup = 200,
  iter_sampling = 100,
  save_warmup = TRUE,
  chains = 2, 
  parallel_chains = 2,
  refresh = 10
  )
  #fit_se[[c]]$save_output_files(dir = paste0(base_path,"Output"), basename = paste0('fcst_training_se_', as.character(i), '_country_' , countries[c]), timestamp = TRUE, random = TRUE)
}
```

```{r}
for (c in length(countries)){
  # post_mean_bm = fit_bm[[c]]$summary(variables = params)$mean
  # fit_bm[[c]]$summary(variables = append(params, 'lp__'))
  
  post_mean_se = fit_se[[c]]$summary(variables = params)$mean
  fit_se[[c]]$summary(variables = append(params, 'lp__'))
}
```

```{r}
post_samples_se = list()
for (c in length(countries)){
  post_samples_se[[c]] = fit_se[[c]]$draws(format = "df",  inc_warmup = F)
  post_samples_se[[c]]$chain = as.character(post_samples_se[[c]]$.chain)
  for (i in 1:length(params)){
    gg = ggplot(data=post_samples_se[[c]], aes_string(x=".iteration", y = params[i], color="chain"))+
    geom_line() + theme_minimal() + ggtitle('SE')
    print(gg)
  }
}
```

Optimsation for SE kernel
```{r}
RMSE = c(); MAE = c()
i =1
for (i in 1:cv_num){
  N2_tes = length(ix_tes[[c]][[i]])
  N2_tr = length(ix_tr[[c]][[i]])
  data = list(N1 = N1[[c]], N2 = length(ix_tr[[c]][[i]]), X1 = X1[[c]], X2 = X2_tr[[c]][[i]], y = z_tr[[c]][[i]])
  fit_optim = mod$optimize(data = data, seed=123)
  post_mean = fit_optim$summary(variables = params)$estimate
  data_pred = list(N1 = N1[[c]], N2 = length(ix_tr[[c]][[i]]),
            X1 = X1[[c]], X2 = X2_tr[[c]][[i]], y = z_tr[[c]][[i]], 
            n1 = N1[[c]], n2 = N2_tes[[c]],
            x1_new = X1[[c]],  x2_new = X2_tes[[c]][[i]],
            alpha0 = fit_optim$summary(variables = 'alpha0')$estimate, 
            alpha1 = fit_optim$summary(variables = 'alpha1')$estimate, 
            alpha2 = fit_optim$summary(variables = 'alpha2')$estimate, 
            rho1 = fit_optim$summary(variables = 'rho1')$estimate, 
            rho2 = fit_optim$summary(variables = 'rho2')$estimate, 
            sigma1 = fit_optim$summary(variables = 'sigma1')$estimate,
            sigma = fit_optim$summary(variables = 'sigma')$estimate
            )
  rm(fit_optim)
  pred = modpred$sample(
    data = data_pred, 
    iter_warmup = 1,
    iter_sampling = 1000,
    chains = 1, 
    refresh = 100,
    fixed_param = TRUE)
  predfit = rstan::read_stan_csv(pred$output_files())
  #pred$save_output_files(dir = paste0(base_path,"Output"), basename = paste0('fcst_se_',as.character(i), '_',country), timestamp = TRUE, random = TRUE)
  post_z_samples = pred$draws(format = "df",  inc_warmup = F)
  post_y_samples = 100/(1+exp(-post_z_samples[,1:(N1[[c]]*N2_tes)]))
  df_pred = as.data.frame(matrix(NA, N1[[c]]*N2_tes,0))
  df_pred$y_hat = colMeans(post_y_samples)
  df_pred$y_true = y_tes[[c]][[i]]
  df_pred$y_residual = df_pred$y_hat - df_pred$y_true
  df_pred$region = rep(df_loc$region, each = N2_tes)
  df_pred$Datetime = rep(as.Date(df$Datetime[1:N2[[c]]][ix_tes[[c]][[i]]], tz='GMT'), times=N1[[c]])
  RMSE[i] = sqrt(mean((df_pred$y_residual)^2))
  MAE[i] = mean(sqrt((df_pred$y_residual)^2))
  cat('RMSE for', country_list[c], ':', RMSE[i],'\n')
  cat('MAE for', country_list[c], ':', MAE[i],'\n')
  write.csv(df_pred,paste0(base_path,'Output/cv_fcst_se_',as.character(i), '_', country,'.csv'))
  post_y_samples = cbind(post_y_samples, post_z_samples[,(N1*N2_tes+1):dim(post_z_samples)[2]])
  write.csv(post_y_samples,paste0(base_path,'Output/post_samples_cv_fcst_se_',as.character(i), '_', country,'.csv'))
}
mean(RMSE);
mean(MAE);
```

```{r}
gg = ggplot(df_plot, aes(x=Datetime, y=FCS, color=region)) + geom_line()+theme_minimal()+
xlim(as.Date("2021-01-01"),df_plot$Datetime[length(df_plot$Datetime)])
gg

```





Optimsation for exp kernel
```{r}
#RMSE = c(); MAE = c()
for (i in 1:cv_num){
  N2_tes = length(ix_tes[[i]])
  N2_tr = length(ix_tr[[i]])
  data = list(N1 = N1, N2 = N2_tr, X1 = X1, X2 = c(X2_tr[[i]]), y = z_tr[[i]])
  fit_optim = mod$optimize(data = data, seed=172)
  post_mean = fit_optim$summary(variables = params)$estimate
  data_pred = list(N1 = N1, N2 = N2_tr,
            X1 = X1, X2 = X2_tr[[i]], y = z_tr[[i]], 
            n1 = N1, n2 = N2_tes,
            x1_new = X1,  x2_new = X2_tes[[i]],
            alpha0 = fit_optim$summary(variables = 'alpha0')$estimate, 
            alpha1 = fit_optim$summary(variables = 'alpha1')$estimate, 
            alpha2 = fit_optim$summary(variables = 'alpha2')$estimate, 
            rho1 = fit_optim$summary(variables = 'rho1')$estimate, 
            rho2 = fit_optim$summary(variables = 'rho2')$estimate, 
            sigma = fit_optim$summary(variables = 'sigma')$estimate
            )
  rm(fit_optim)
  pred = modpred$sample(
  data = data_pred, 
  iter_warmup = 1,
  iter_sampling = 1000,
  chains = 1, 
  refresh = 100,
  fixed_param = TRUE)
  predfit = rstan::read_stan_csv(pred$output_files())
  pred$save_output_files(dir = paste0(base_path,"Output"), basename = paste0('fcst_exponential_',as.character(i), '_',country), timestamp = TRUE, random = TRUE)
  post_z_samples = pred$draws(format = "df",  inc_warmup = F)
  post_y_samples = 100/(1+exp(-post_z_samples[,1:(N1*N2_tes)]))
  df_pred = as.data.frame(matrix(NA, N1*N2_tes,0))
  df_pred$y_hat = colMeans(post_y_samples)
  df_pred$y_true = y_tes[[i]]
  df_pred$y_residual = df_pred$y_hat - df_pred$y_true
  df_pred$region = rep(df_loc$region, each = N2_tes)
  df_pred$Datetime = rep(as.Date(df$Datetime[1:N2][ix_tes[[i]]], tz='GMT'), times=N1)
  RMSE[i] = sqrt(mean((df_pred$y_residual)^2))
  MAE[i] = mean(sqrt((df_pred$y_residual)^2))
  cat('RMSE for', country, ':', RMSE[i],'\n')
  cat('MAE for', country, ':', MAE[i],'\n')
  write.csv(df_pred, paste0(base_path,'Output/cv_fcst_exponential_',as.character(i), '_', country,'.csv'))
  post_y_samples = cbind(post_y_samples, post_z_samples[,(N1*N2_tes+1):dim(post_z_samples)[2]])
  write.csv(post_y_samples,paste0(base_path,'Output/post_samples_cv_fcst_exponential_',as.character(i), '_', country,'.csv'))
}
mean(RMSE);
mean(MAE);
# Burkina Faso
#7.286001
#5.969191
```

Plot
```{r}
for (i in 1:cv_num){
    df_pred =  read.csv(paste0(base_path, '/Output/cv_fcst_exponential_', as.character(i), '_', country,'.csv'), header = TRUE)
  df_pred$Datetime = as.POSIXct(df_pred$Datetime)
  gg = ggplot(df_pred, aes(x=Datetime,y=y_residual,color=region)) + geom_line() 
  print(gg)
}
```

#Plot
```{r}
i = 1
N2_tes = length(ix_tes[[i]])
N2_tr = length(ix_tr[[i]])
df_plot = df
Y_pred = matrix(NA, N2,N1)
Y_true = matrix(NA, N2,N1)
Y_pred[ix_tr[[i]],] = Y[ix_tr[[i]],]
Y_true[ix_tr[[i]],] = Y[ix_tr[[i]],]
Y_pred[ix_tes[[i]],] = matrix(df_pred$y_hat, N2_tes, N1)
df_plot$training = c(Y_true)
df_plot$forecast = c(Y_pred)
Y_true[ix_tes[[i]],] = Y[ix_tes[[i]],]
df_plot$true = c(Y_true)
df_plot$error = df_plot$forecast - df_plot$true 
df_plot = df_plot[is.na(df_plot$forecast)!=TRUE,]
```

```{r}
y_max = max(df_plot$true); y_min = min(df_plot$true)
date_th = df_plot$Datetime[N2_tr]
gg_tr = ggplot(df_plot, aes(x=Datetime,y=forecast,color=region)) + geom_line() + ylim(y_min,y_max)  +
 #xlim(as.Date("2021-09-01"),df_plot$Datetime[length(df_plot$Datetime)])+
       geom_vline(xintercept = date_th,linetype=4) 
gg_tr
gg_pred = ggplot(df_plot, aes(x=Datetime,y=true,color=region)) + geom_line() + ylim(y_min,y_max)  +
  #xlim(as.Date("2021-09-01"),df_plot$Datetime[length(df_plot$Datetime)])+
       geom_vline(xintercept = date_th,linetype=4)
gg_pred
gg = ggplot(df_plot, aes(x=Datetime,y=training,color=region)) + geom_line() + ylim(y_min,y_max) #+
 #xlim(as.Date("2021-09-01"),df_plot$Datetime[length(df_plot$Datetime)])
gg
```


